{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "airlines = pd.read_csv('airlines_final.csv')\n",
    "# This one is a bit different, no 'unacceptable' cleanliness category\n",
    "\n",
    "categories_data = {\n",
    "    'cleanliness': ['Clean', 'Average', 'Somewhat clean', 'Somewhat dirty', 'Dirty'],\n",
    "    'safety': ['Neutral', 'Very safe', 'Somewhat safe', 'Very unsafe', 'Somewhat unsafe'],\n",
    "    'satisfaction': ['Very satisfied', 'Neutral', 'Somewhat satisfied', 'Somewhat unsatisfied', 'Very unsatisfied']\n",
    "}\n",
    "\n",
    "categories = pd.DataFrame(categories_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding consistency\n",
    "===================\n",
    "\n",
    "In this exercise and throughout this chapter, you'll be working with the `airlines` DataFrame which contains survey responses on the San Francisco Airport from airline customers.\n",
    "\n",
    "The DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction. Another DataFrame named `categories` was created, containing all correct possible values for the survey columns.\n",
    "\n",
    "In this exercise, you will use both of these DataFrames to find survey answers with inconsistent values, and drop them, effectively performing an outer and inner join on both these DataFrames as seen in the video exercise. The `pandas` package has been imported as `pd`, and the `airlines` and `categories` DataFrames are in your environment.\n",
    "\n",
    "### Instructions 1/4 - 35 XP\n",
    "\n",
    "*   Print the `categories` DataFrame and take a close look at all possible correct categories of the survey columns.\n",
    "*   Print the unique values of the survey columns in `airlines` using the `.unique()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cleanliness           safety          satisfaction\n",
      "0           Clean          Neutral        Very satisfied\n",
      "1         Average        Very safe               Neutral\n",
      "2  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
      "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
      "4           Dirty  Somewhat unsafe      Very unsatisfied\n",
      "Cleanliness:  ['Clean' 'Average' 'Somewhat clean' 'Somewhat dirty' 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satsified' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print categories DataFrame\n",
    "print(categories)\n",
    "\n",
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")\n",
    "\n",
    "\n",
    "# # Print categories DataFrame\n",
    "# print(____)\n",
    "\n",
    "# # Print unique values of survey columns in airlines\n",
    "# print('Cleanliness: ', airlines['cleanliness'].____, \"\\n\")\n",
    "# print('Safety: ', ____, \"\\n\")\n",
    "# print('Satisfaction: ', ____, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions 2/4 - 15 XP\n",
    "\n",
    "Question\n",
    "\n",
    "Take a look at the output. Out of the `cleanliness`, `safety` and `satisfaction` columns, which one has an inconsistent category and what is it?\n",
    "\n",
    "Possible answers\n",
    "\n",
    "*   `cleanliness` because it has an `Unacceptable` category.\n",
    "\n",
    "*   `cleanliness` because it has a `Terribly dirty` category.\n",
    "\n",
    "*   `satisfaction` because it has a `Very satisfied` category. <--->\n",
    "\n",
    "*   `safety` because it has a `Neutral` category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions 3/4 - 25 XP\n",
    "\n",
    "*   Create a set out of the `cleanliness` column in `airlines` using `set()` and find the inconsistent category by finding the **difference** in the `cleanliness` column of `categories`.\n",
    "*   Find rows of `airlines` with a `cleanliness` value not in `categories` and print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, id, day, airline, destination, dest_region, dest_size, boarding_area, dept_time, wait_min, cleanliness, safety, satisfaction]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "print(airlines[cat_clean_rows])\n",
    "\n",
    "\n",
    "# # Find the cleanliness category in airlines not in categories\n",
    "# cat_clean = ____(____).____(____)\n",
    "\n",
    "# # Find rows with that category\n",
    "# cat_clean_rows = airlines['cleanliness'].____(____)\n",
    "\n",
    "# # Print rows with inconsistent category\n",
    "# print(airlines[____])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions 4/4 - 25 XP\n",
    "\n",
    "*   Print the rows with the consistent categories of `cleanliness` only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, id, day, airline, destination, dest_region, dest_size, boarding_area, dept_time, wait_min, cleanliness, safety, satisfaction]\n",
      "Index: []\n",
      "      Unnamed: 0    id        day        airline        destination  \\\n",
      "0              0  1351    Tuesday    UNITED INTL             KANSAI   \n",
      "1              1   373     Friday         ALASKA  SAN JOSE DEL CABO   \n",
      "2              2  2820   Thursday          DELTA        LOS ANGELES   \n",
      "3              3  1157    Tuesday      SOUTHWEST        LOS ANGELES   \n",
      "4              4  2992  Wednesday       AMERICAN              MIAMI   \n",
      "...          ...   ...        ...            ...                ...   \n",
      "2472        2804  1475    Tuesday         ALASKA       NEW YORK-JFK   \n",
      "2473        2805  2222   Thursday      SOUTHWEST            PHOENIX   \n",
      "2474        2806  2684     Friday         UNITED            ORLANDO   \n",
      "2475        2807  2549    Tuesday        JETBLUE         LONG BEACH   \n",
      "2476        2808  2162   Saturday  CHINA EASTERN            QINGDAO   \n",
      "\n",
      "        dest_region dest_size boarding_area   dept_time  wait_min  \\\n",
      "0              Asia       Hub  Gates 91-102  2018-12-31     115.0   \n",
      "1     Canada/Mexico     Small   Gates 50-59  2018-12-31     135.0   \n",
      "2           West US       Hub   Gates 40-48  2018-12-31      70.0   \n",
      "3           West US       Hub   Gates 20-39  2018-12-31     190.0   \n",
      "4           East US       Hub   Gates 50-59  2018-12-31     559.0   \n",
      "...             ...       ...           ...         ...       ...   \n",
      "2472        East US       Hub   Gates 50-59  2018-12-31     280.0   \n",
      "2473        West US       Hub   Gates 20-39  2018-12-31     165.0   \n",
      "2474        East US       Hub   Gates 70-90  2018-12-31      92.0   \n",
      "2475        West US     Small    Gates 1-12  2018-12-31      95.0   \n",
      "2476           Asia     Large    Gates 1-12  2018-12-31     220.0   \n",
      "\n",
      "         cleanliness         safety        satisfaction  \n",
      "0              Clean        Neutral      Very satisfied  \n",
      "1              Clean      Very safe      Very satisfied  \n",
      "2            Average  Somewhat safe             Neutral  \n",
      "3              Clean      Very safe  Somewhat satsified  \n",
      "4     Somewhat clean      Very safe  Somewhat satsified  \n",
      "...              ...            ...                 ...  \n",
      "2472  Somewhat clean        Neutral  Somewhat satsified  \n",
      "2473           Clean      Very safe      Very satisfied  \n",
      "2474           Clean      Very safe      Very satisfied  \n",
      "2475           Clean  Somewhat safe      Very satisfied  \n",
      "2476           Clean      Very safe  Somewhat satsified  \n",
      "\n",
      "[2477 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "print(airlines[cat_clean_rows])\n",
    "\n",
    "# Print rows with consistent categories only\n",
    "print(airlines[~cat_clean_rows])\n",
    "\n",
    "\n",
    "# # Find the cleanliness category in airlines not in categories\n",
    "# cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# # Find rows with that category\n",
    "# cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# # Print rows with inconsistent category\n",
    "# print(airlines[cat_clean_rows])\n",
    "\n",
    "# # Print rows with consistent categories only\n",
    "# print(airlines[____])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inconsistent categories\n",
    "=======================\n",
    "\n",
    "In this exercise, you'll be revisiting the `airlines` DataFrame from the previous lesson.\n",
    "\n",
    "As a reminder, the DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction on the San Francisco Airport.\n",
    "\n",
    "In this exercise, you will examine two categorical columns from this DataFrame, `dest_region` and `dest_size` respectively, assess how to address them and make sure that they are cleaned and ready for analysis. The `pandas` package has been imported as `pd`, and the `airlines` DataFrame is in your environment.\n",
    "\n",
    "### Instructions 1/4\n",
    "\n",
    "25 XP\n",
    "\n",
    "*   Print the unique values in `dest_region` and `dest_size` respectively.\n",
    "\n",
    "Take Hint (-7 XP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "\n",
    "# # Print unique values of both columns\n",
    "# print(airlines['dest_region'].____())\n",
    "# print(airlines['____'].____())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions 2/4\n",
    "\n",
    "Question\n",
    "\n",
    "From looking at the output, what do you think is the problem with these columns?\n",
    "\n",
    "Possible answers\n",
    "\n",
    "*   The `dest_region` column has only inconsistent values due to capitalization.\n",
    "\n",
    "*   The `dest_region` column has inconsistent values due to capitalization and has one value that needs to be remapped.\n",
    "\n",
    "*   The `dest_size` column has only inconsistent values due to leading and trailing spaces.\n",
    "\n",
    "*   Both 2 and 3 are correct. <--->\n",
    "\n",
    "Submit Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions 3/4\n",
    "\n",
    "*   Change the capitalization of all values of `dest_region` to lowercase.\n",
    "*   Replace the `'eur'` with `'europe'` in `dest_region` using the `.replace()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "\n",
    "# # Print unique values of both columns\n",
    "# print(airlines['dest_region'].unique())\n",
    "# print(airlines['dest_size'].unique())\n",
    "\n",
    "# # Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "# airlines['dest_region'] = airlines['dest_region'].____.____()\n",
    "# airlines['dest_region'] = airlines['dest_region'].____({'____':'____'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions 4/4\n",
    "\n",
    "*   Strip white spaces from the `dest_size` column using the `.strip()` method.\n",
    "*   Verify that the changes have been into effect by printing the unique values of the columns using `.unique()` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower() \n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "\n",
    "\n",
    "# # Print unique values of both columns\n",
    "# print(airlines['dest_region'].unique())\n",
    "# print(airlines['dest_size'].unique())\n",
    "\n",
    "# # Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "# airlines['dest_region'] = airlines['dest_region'].str.lower() \n",
    "# airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "# # Remove white spaces from `dest_size`\n",
    "# airlines['dest_size'] = airlines['dest_size'].____.____()\n",
    "\n",
    "# # Verify changes have been effected\n",
    "# print(____)\n",
    "# print(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remapping categories\n",
    "====================\n",
    "\n",
    "To better understand survey respondents from `airlines`, you want to find out if there is a relationship between certain responses and the day of the week and wait time at the gate.\n",
    "\n",
    "The `airlines` DataFrame contains the `day` and `wait_min` columns, which are categorical and numerical respectively. The `day` column contains the exact day a flight took place, and `wait_min` contains the amount of minutes it took travelers to wait at the gate. To make your analysis easier, you want to create two new categorical variables:\n",
    "\n",
    "*   `wait_type`: `'short'` for 0-60 min, `'medium'` for 60-180 and `long` for 180+\n",
    "*   `day_week`: `'weekday'` if day is in the weekday, `'weekend'` if day is in the weekend.\n",
    "\n",
    "The `pandas` and `numpy` packages have been imported as `pd` and `np`. Let's create some new categorical data!\n",
    "\n",
    "Instructions - 100 XP\n",
    "\n",
    "*   Create the ranges and labels for the `wait_type` column mentioned in the description.\n",
    "*   Create the `wait_type` column by from `wait_min` by using `pd.cut()`, while inputting `label_ranges` and `label_names` in the correct arguments.\n",
    "*   Create the `mapping` dictionary mapping weekdays to `'weekday'` and weekend days to `'weekend'`.\n",
    "*   Create the `day_week` column by using `.replace()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)\n",
    "\n",
    "\n",
    "# # Create ranges for categories\n",
    "# label_ranges = [0, 60, ____, np.inf]\n",
    "# label_names = ['short', ____, ____]\n",
    "\n",
    "# # Create wait_type column\n",
    "# airlines['wait_type'] = pd.____(____, bins = ____, \n",
    "#                                 labels = ____)\n",
    "\n",
    "# # Create mappings and replace\n",
    "# mappings = {'Monday':'weekday', 'Tuesday':'____', 'Wednesday': '____', \n",
    "#             'Thursday': '____', '____': '____', \n",
    "#             'Saturday': 'weekend', '____': '____'}\n",
    "\n",
    "# airlines['day_week'] = airlines['day'].____(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing titles and taking names\n",
    "\n",
    "While collecting survey respondent metadata in the `airlines` DataFrame, the full name of respondents was saved in the `full_name` column. However upon closer inspection, you found that a lot of the different names are prefixed by honorifics such as `\"Dr.\"`, `\"Mr.\"`, `\"Ms.\"` and `\"Miss\"`.\n",
    "\n",
    "Your ultimate objective is to create two new columns named `first_name` and `last_name`, containing the first and last names of respondents respectively. Before doing so however, you need to remove honorifics.\n",
    "\n",
    "The `airlines` DataFrame is in your environment, alongside `pandas` as `pd.`\n",
    "\n",
    "Instructions\n",
    "\n",
    "100 XP\n",
    "\n",
    "*   Remove `\"Dr.\"`, `\"Mr.\"`, `\"Miss\"` and `\"Ms.\"` from `full_name` by replacing them with an empty string `\"\"` in that order.\n",
    "*   Run the `assert` statement using `.str.contains()` that tests whether `full_name` still contains any of the honorifics.\n",
    "\n",
    "Take Hint (-30 XP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'full_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'full_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\DA\\Courses - DataCamp\\Data Engineer\\11 Cleaning Data in Python\\Part2.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DA/Courses%20-%20DataCamp/Data%20Engineer/11%20Cleaning%20Data%20in%20Python/Part2.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Replace \"Dr.\" with empty string \"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DA/Courses%20-%20DataCamp/Data%20Engineer/11%20Cleaning%20Data%20in%20Python/Part2.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m airlines[\u001b[39m'\u001b[39m\u001b[39mfull_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m airlines[\u001b[39m'\u001b[39;49m\u001b[39mfull_name\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mDr.\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DA/Courses%20-%20DataCamp/Data%20Engineer/11%20Cleaning%20Data%20in%20Python/Part2.ipynb#X61sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Replace \"Mr.\" with empty string \"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DA/Courses%20-%20DataCamp/Data%20Engineer/11%20Cleaning%20Data%20in%20Python/Part2.ipynb#X61sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m airlines[\u001b[39m'\u001b[39m\u001b[39mfull_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m airlines[\u001b[39m'\u001b[39m\u001b[39mfull_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mMr.\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'full_name'"
     ]
    }
   ],
   "source": [
    "# Replace \"Dr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\",\"\")\n",
    "\n",
    "# Replace \"Mr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\",\"\")\n",
    "\n",
    "# Replace \"Miss\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Miss\",\"\")\n",
    "\n",
    "# Replace \"Ms.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\",\"\")\n",
    "\n",
    "# Assert that full_name has no honorifics\n",
    "assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False\n",
    "\n",
    "\n",
    "# # Replace \"Dr.\" with empty string \"\"\n",
    "# airlines['full_name'] = airlines['full_name'].____.____(\"____\",\"\")\n",
    "\n",
    "# # Replace \"Mr.\" with empty string \"\"\n",
    "# airlines['full_name'] = ____\n",
    "\n",
    "# # Replace \"Miss\" with empty string \"\"\n",
    "# ____\n",
    "\n",
    "# # Replace \"Ms.\" with empty string \"\"\n",
    "# ____\n",
    "\n",
    "# # Assert that full_name has no honorifics\n",
    "# assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Keeping it descriptive\n",
    "======================\n",
    "\n",
    "To further understand travelers' experiences in the San Francisco Airport, the quality assurance department sent out a qualitative questionnaire to all travelers who gave the airport the worst score on all possible categories. The objective behind this questionnaire is to identify common patterns in what travelers are saying about the airport.\n",
    "\n",
    "Their response is stored in the `survey_response` column. Upon a closer look, you realized a few of the answers gave the shortest possible character amount without much substance. In this exercise, you will isolate the responses with a character count higher than **_40_** , and make sure your new DataFrame contains responses with **_40_** characters or more using an `assert` statement.\n",
    "\n",
    "The `airlines` DataFrame is in your environment, and `pandas` is imported as `pd`.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "100 XP\n",
    "\n",
    "*   Using the `airlines` DataFrame, store the length of each instance in the `survey_response` column in `resp_length` by using `.str.len()`.\n",
    "*   Isolate the rows of `airlines` with `resp_length` higher than `40`.\n",
    "*   Assert that the smallest `survey_response` length in `airlines_survey` is now bigger than `40`.\n",
    "\n",
    "Take Hint (-30 XP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'survey_response'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'survey_response'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\DA\\Courses - DataCamp\\Data Engineer\\11 Cleaning Data in Python\\Part2.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DA/Courses%20-%20DataCamp/Data%20Engineer/11%20Cleaning%20Data%20in%20Python/Part2.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Store length of each row in survey_response column\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DA/Courses%20-%20DataCamp/Data%20Engineer/11%20Cleaning%20Data%20in%20Python/Part2.ipynb#X63sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m resp_length \u001b[39m=\u001b[39m airlines[\u001b[39m'\u001b[39;49m\u001b[39msurvey_response\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mlen()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DA/Courses%20-%20DataCamp/Data%20Engineer/11%20Cleaning%20Data%20in%20Python/Part2.ipynb#X63sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Find rows in airlines where resp_length > 40\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DA/Courses%20-%20DataCamp/Data%20Engineer/11%20Cleaning%20Data%20in%20Python/Part2.ipynb#X63sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m airlines_survey \u001b[39m=\u001b[39m airlines[resp_length \u001b[39m>\u001b[39m \u001b[39m40\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Raihan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'survey_response'"
     ]
    }
   ],
   "source": [
    "# Store length of each row in survey_response column\n",
    "resp_length = airlines['survey_response'].str.len()\n",
    "\n",
    "# Find rows in airlines where resp_length > 40\n",
    "airlines_survey = airlines[resp_length > 40]\n",
    "\n",
    "# Assert minimum survey_response length is > 40\n",
    "assert airlines_survey['survey_response'].str.len().min() > 40\n",
    "\n",
    "# Print new survey_response column\n",
    "print(airlines_survey['survey_response'])\n",
    "\n",
    "\n",
    "# # Store length of each row in survey_response column\n",
    "# resp_length = ____\n",
    "\n",
    "# # Find rows in airlines where resp_length > 40\n",
    "# airlines_survey = airlines[____ > ____]\n",
    "\n",
    "# # Assert minimum survey_response length is > 40\n",
    "# assert ____.str.len().____ > _____\n",
    "\n",
    "# # Print new survey_response column\n",
    "# print(airlines_survey['survey_response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
